{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a08df3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hp\\.cache\\huggingface\\hub\\datasets--Cynaptics--persona-chat. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Generating train split: 100%|██████████| 20000/20000 [00:00<00:00, 87833.86 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Model Evaluation...\n",
      "Device: cpu\n",
      "Model: ./model_artifacts\n",
      "\n",
      "Calculating perplexity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating perplexity: 100%|██████████| 100/100 [04:51<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 3.31\n",
      "\n",
      "\n",
      "================================================================================\n",
      "QUALITATIVE EVALUATION - Sample Generations\n",
      "================================================================================\n",
      "\n",
      "Sample 1:\n",
      "Persona: I would love to try the local food with my friend. i am quiet but confident. I love to watch movies with my dad on a rainy day. i try to limit how much i eat. I just finished practicing my bass guitar in the lifeguard station.\n",
      "\n",
      "Generated Response:\n",
      "persona: I would love to try the local food with my friend. i am quiet but confident. I love to watch movies with my dad on a rainy day. i try to limit how much i eat. I just finished practicing my bass guitar in the lifeguard station. dialogue: Persona A: Hello! Persona B: Hello, how are you doing? Persona A: I'm doing well, just finished practicing my bass guitar. Persona B: That's awesome! I love to play bass guitar. Persona A: It is a lot of fun! I've played for about 10 years now. Persona B: That's really impressive! What kind of music do you like to play? Persona A: I like to play a variety of music, but my favorite is probably rock and roll. Persona B: I also like rock and roll! What's your favorite band? Persona A: I like a lot of different bands, but my favorite is probably The Beatles\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sample 2:\n",
      "Persona: I am most proud of my ability to connect with nature and animals. I have never been arrested, but my stories might make you think otherwise. i love family time. my parents both are school teachers. I'm afraid of being in a situation where I can't communicate with my wife.\n",
      "\n",
      "Generated Response:\n",
      "persona: I am most proud of my ability to connect with nature and animals. I have never been arrested, but my stories might make you think otherwise. i love family time. my parents both are school teachers. I'm afraid of being in a situation where I can't communicate with my wife. dialogue: Persona A: I love the outdoors! I love to go hiking and camping. Persona B: I love to go hiking too! I love the fresh air and the feeling of being in nature. Persona A: Me too! I love being outside and enjoying the fresh air. Persona B: What are some of your favorite things to do outdoors? Persona A: I love to go fishing, hiking, and camping. Persona B: Those all sound like great ways to spend time outdoors! I love going to the beach too. Persona A: Me too! I love the feeling of the sun and the sand, and the sound of the waves. Persona B: I love the\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sample 3:\n",
      "Persona: I enjoy my family and do not care about socializing. i m bored with my current lifestyle. i currently suffer from social anxiety. I exercise three times a week to maintain a healthy lifestyle. I'm looking for a home with a large closet so I can have plenty of space for my sewing supplies.\n",
      "\n",
      "Generated Response:\n",
      "persona: I enjoy my family and do not care about socializing. i m bored with my current lifestyle. i currently suffer from social anxiety. I exercise three times a week to maintain a healthy lifestyle. I'm looking for a home with a large closet so I can have plenty of space for my sewing supplies. dialogue: Persona A: Hello, I'm a little bored with my current lifestyle. Persona B: I'm glad to hear that. Persona A: I'm from the Midwest, where are you from? Persona B: I'm from the East Coast, but I'm enjoying the Midwest here. Persona A: I'm from the Midwest too! I'm a huge fan of the Midwest food. Persona B: Me too! I love my family and do not care about socializing. Persona A: I love my family too! I'm a big fan of the Beatles and they're my favorite band. Persona B: I'm a\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sample 4:\n",
      "Persona: I will continue to play music with my friends to help relieve stress and enjoy myself. I try to keep in touch with my family, but I can be busy with school and my job. i enjoy cooking but not baking. i can speak arabic , english , and french. My biggest fear is that I will work myself up so much that I will become ill.\n",
      "\n",
      "Generated Response:\n",
      "persona: I will continue to play music with my friends to help relieve stress and enjoy myself. I try to keep in touch with my family, but I can be busy with school and my job. i enjoy cooking but not baking. i can speak arabic , english , and french. My biggest fear is that I will work myself up so much that I will become ill. dialogue: Persona A: I am doing well, thanks for asking! I am a musician and I love to play music with my friends. Persona B: That sounds like a fun job! I am a stay-at-home mom, but I love to cook and bake. Persona A: I love to cook too! I am not very good at it, but I enjoy trying new recipes. Persona B: I love trying new recipes too! I am always looking for new ways to improve my cooking. Persona A: I am glad to hear that! I love to cook, but I am not very good at\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sample 5:\n",
      "Persona: I like to wear the same pants every day so I don't have to think about what to wear. I enjoy helping my community by serving on the city council. i love the rain. I like mangoes because they are sweet and juicy. my favorite basketball team is the vancouver grizzlies.\n",
      "\n",
      "Generated Response:\n",
      "persona: I like to wear the same pants every day so I don't have to think about what to wear. I enjoy helping my community by serving on the city council. i love the rain. I like mangoes because they are sweet and juicy. my favorite basketball team is the vancouver grizzlies. dialogue: Persona A: I like to go hiking in the mountains and take pictures of the views. Persona B: I like to go hiking in the mountains too. I love the fresh air and the feeling of being outdoors. Persona A: I also like the feeling of being in nature. I like to go for walks in the park and listen the birds singing. Persona B: I love the rain too. It is so beautiful and refreshing. Persona A: It is also a great way to clear your head. Persona B: I agree. I like to spend time in nature to relax and clear my mind. Persona A: I agree. I like to go for walks in\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Evaluation complete! Results saved to evaluation_results.json\n",
      "\n",
      "Final Results:\n",
      "Perplexity: 3.31\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model_path = \"./model_artifacts\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load test dataset\n",
    "ds = load_dataset(\"Cynaptics/persona-chat\")\n",
    "\n",
    "# If there's a test split, use it; otherwise, split the train set\n",
    "if \"test\" in ds:\n",
    "    test_ds = ds[\"test\"]\n",
    "elif \"validation\" in ds:\n",
    "    test_ds = ds[\"validation\"]\n",
    "else:\n",
    "    # Take a small portion of training data for evaluation\n",
    "    test_ds = ds[\"train\"].select(range(100))\n",
    "\n",
    "def combine_persona_dialogue(entry):\n",
    "    \"\"\"Combines the persona and dialogue into input format\"\"\"\n",
    "    persona_text = \" \".join(entry[\"persona_b\"])\n",
    "    dialogue_text = \" \".join(entry[\"dialogue\"])\n",
    "    return f\"persona: {persona_text} dialogue: {dialogue_text}\"\n",
    "\n",
    "def generate_response(prompt, max_length=150, temperature=0.7, top_p=0.9):\n",
    "    \"\"\"Generate response from the model\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=max_length,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "def calculate_perplexity(model, tokenizer, dataset, max_samples=100):\n",
    "    \"\"\"Calculate perplexity on the dataset\"\"\"\n",
    "    total_loss = 0\n",
    "    total_tokens = 0\n",
    "    \n",
    "    for i in tqdm(range(min(max_samples, len(dataset))), desc=\"Calculating perplexity\"):\n",
    "        text = combine_persona_dialogue(dataset[i])\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "            loss = outputs.loss\n",
    "            \n",
    "        total_loss += loss.item() * inputs[\"input_ids\"].size(1)\n",
    "        total_tokens += inputs[\"input_ids\"].size(1)\n",
    "    \n",
    "    perplexity = np.exp(total_loss / total_tokens)\n",
    "    return perplexity\n",
    "\n",
    "def qualitative_evaluation(dataset, num_samples=5):\n",
    "    \"\"\"Generate sample outputs for qualitative evaluation\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"QUALITATIVE EVALUATION - Sample Generations\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    for i in range(min(num_samples, len(dataset))):\n",
    "        entry = dataset[i]\n",
    "        persona_text = \" \".join(entry[\"persona_b\"])\n",
    "        \n",
    "        # Create a prompt with just the persona\n",
    "        prompt = f\"persona: {persona_text} dialogue:\"\n",
    "        \n",
    "        print(f\"Sample {i+1}:\")\n",
    "        print(f\"Persona: {persona_text}\")\n",
    "        print(f\"\\nGenerated Response:\")\n",
    "        generated = generate_response(prompt, max_length=200)\n",
    "        print(generated)\n",
    "        print(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "\n",
    "def evaluate_model(test_dataset, num_perplexity_samples=100, num_qualitative_samples=5):\n",
    "    \"\"\"Run full evaluation\"\"\"\n",
    "    print(\"Starting Model Evaluation...\")\n",
    "    print(f\"Device: {device}\")\n",
    "    print(f\"Model: {model_path}\\n\")\n",
    "    \n",
    "    # Calculate perplexity\n",
    "    print(\"Calculating perplexity...\")\n",
    "    perplexity = calculate_perplexity(model, tokenizer, test_dataset, num_perplexity_samples)\n",
    "    print(f\"Perplexity: {perplexity:.2f}\\n\")\n",
    "    \n",
    "    # Qualitative evaluation\n",
    "    qualitative_evaluation(test_dataset, num_qualitative_samples)\n",
    "    \n",
    "    # Save results\n",
    "    results = {\n",
    "        \"model_path\": model_path,\n",
    "        \"perplexity\": float(perplexity),\n",
    "        \"num_samples_evaluated\": num_perplexity_samples,\n",
    "        \"device\": device\n",
    "    }\n",
    "    \n",
    "    with open(\"evaluation_results.json\", \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    print(\"Evaluation complete! Results saved to evaluation_results.json\")\n",
    "    return results\n",
    "\n",
    "# Run evaluation\n",
    "if __name__ == \"__main__\":\n",
    "    results = evaluate_model(\n",
    "        test_dataset=test_ds,\n",
    "        num_perplexity_samples=100,  # Adjust based on your needs\n",
    "        num_qualitative_samples=5     # Number of sample generations to display\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nFinal Results:\")\n",
    "    print(f\"Perplexity: {results['perplexity']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
